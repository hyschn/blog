---
title: 机器学习中的数学(1)-线性代数
tags: 机器学习 线性代数 数学
key: 20181107
---
## 基本概念
* 标量(scalar)  
一个标量就是一个单独的数.
* 向量(vector)  
一个向量是一列数,通过序列中的索引,可以确定每个单独的数.
* 矩阵(matrix)  
矩阵是一个二维数组，其中的每一个元素由两个索引（而非一个）所确定。  
    * $A_{j,j}$表示矩阵$A$第$i$行第$j$列的元素.
    * $A_{i,:}$表示矩阵$A$垂直坐标$i$上的一行元素.
    * $A_{:,j}$便是矩阵$A$水平坐标$j$上的一列元素.
$$\begin{bmatrix}A_{1,1} & A_{1,2}\\\\A_{2,1} &A_{2,2}\end{bmatrix}$$
* 张量(tensor)  
坐标在$n$維空間內，有$n^r$個分量的一種量.$r$稱為該張量的秩或階（与矩阵的秩和阶均无关系).
* 转置(transpose)  
矩阵A的转置写作$A^{\mathrm{T}}$,并且:
$$A_{ij}^{\mathrm {T} }=A_{ji} for {\displaystyle 1\leq i\leq n,} 1\leq i\leq n, {\displaystyle 1\leq j\leq m} 1\leq j\leq m$$
![](https://upload.wikimedia.org/wikipedia/commons/e/e4/Matrix_transpose.gif)

## 矩阵运算
* 标量和矩阵运算,就是将其与矩阵的的每个元素执行相应的运算  
例如,$D=a \cdot B + c$,其中 $D_{i,j}=a \cdot B_{i,j} + c$
* 矩阵加法   
两个形状一样(行数,列数相等)的矩阵才可以相加,矩阵相加即对应位置元素相加.  
例如$C=A+B$,其中$C_{i,j}=A_{i,j}+B_{i.j}$
* 矩阵乘积(matrix product)  
通常,单说矩阵乘积时,指的是一般矩阵乘积.它只有在第一个矩阵的列数(column)和第二个矩阵的行数(row)相同时才有定义.  
给定两个矩阵$A=(a_{i,j}) \in R^{m,n}$,$B=(b_{i,j})\in R^{n,p}$,则它们的乘积记作$AB或A \cdot B$会是一个$m\times p$的矩阵.其乘积的元素由下面的式子得出:  
$$(AB)_{ij} = \sum_{r=1}^n a_{ir}b_{rj} = a_{i1}b_{1j} + a_{i2}b_{2j} + \cdots + a_{in}b_{nj}$$

## 单位矩阵和逆矩阵  
$n$阶单位矩阵,是一个$n\times n$的方形矩阵,其主对角线元素为1,其余元素为0,记作$I_n$.  
$A$的逆矩阵记作$A^{-1}$,满足以下条件  
$$A\cdot A=I_n$$ 

## 线性相关和生成子空间
一组向量的生成子空间（span）是原始向量线性组合后所能抵达的点的集合。   
确定$Ax=b$是否有解，相当于确定向量$b$是否在$A$列向量的生成子空间中。这个特殊的生成子空间被称为$A$的列空间（column space）或者$A$的值域(range).  
在线性代数里，矢量空间的一组元素中，若没有矢量可用有限个其他矢量的线性组合所表示，则称为线性无关或线性独立 (linearly independent)，反之称为线性相关(linearly dependent)。 
